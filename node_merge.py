# nodes.py (í†µí•© ë²„ì „)

from state import State, Hit, Nutrition, Prefs
from typing import Dict, Any, List, Optional
from pathlib import Path
import faiss
import time, json, re
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
import openai
import os

# ======== ê°„ë‹¨ í‚¤ì›Œë“œ ë§¤í•‘ (í•œê¸€/ì˜ì–´) ========

INGREDIENT_KEYWORDS = {
    # ìœ¡ë¥˜
    "ë‹­": "chicken", "ë‹­ê°€ìŠ´ì‚´": "chicken breast", "ì¹˜í‚¨": "chicken",
    "ì†Œê³ ê¸°": "beef", "ìŠ¤í…Œì´í¬": "steak", "ë¹„í”„": "beef",
    "ë¼ì§€ê³ ê¸°": "pork", "ë¼ì§€": "pork", "ë² ì´ì»¨": "bacon", "í–„": "ham",
    "ì†Œì‹œì§€": "sausage", "ì–‘ê³ ê¸°": "lamb",

    # í•´ì‚°ë¬¼
    "ìƒˆìš°": "shrimp", "ì—°ì–´": "salmon", "ì°¸ì¹˜": "tuna", "ìƒì„ ": "fish",
    "ê²Œ": "crab", "ì¡°ê°œ": "clam",

    # ì±„ì†Œ/ê³¼ì¼
    "ì–‘íŒŒ": "onion", "ë§ˆëŠ˜": "garlic", "íŒŒ": "green onion",
    "ê°ì": "potato", "ê³ êµ¬ë§ˆ": "sweet potato", "í† ë§ˆí† ": "tomato",
    "ë²„ì„¯": "mushroom", "ë‹¹ê·¼": "carrot", "ì‹œê¸ˆì¹˜": "spinach",
    "ì˜¥ìˆ˜ìˆ˜": "corn", "ë¸Œë¡œì½œë¦¬": "broccoli", "ì•„ë³´ì¹´ë„": "avocado",
    "ì‚¬ê³¼": "apple", "ë°”ë‚˜ë‚˜": "banana", "ë”¸ê¸°": "strawberry", "ë ˆëª¬": "lemon",

    # ìœ ì œí’ˆ/ì•Œ
    "ê³„ë€": "egg", "ë‹¬ê±€": "egg", "ì¹˜ì¦ˆ": "cheese", "ìš°ìœ ": "milk",
    "ë²„í„°": "butter", "í¬ë¦¼": "cream", "ìš”ê±°íŠ¸": "yogurt",

    # ê¸°íƒ€
    "ì´ˆì½œë¦¿": "chocolate", "ì´ˆì½”": "chocolate", "ìŒ€": "rice",
    "ë°¥": "rice", "ë©´": "noodle", "íŒŒìŠ¤íƒ€": "pasta", "ë¹µ": "bread",
    "ì„¤íƒ•": "sugar", "ì†Œê¸ˆ": "salt", "ë‘ë¶€": "tofu", "ê¹€ì¹˜": "kimchi",
}

CATEGORY_KEYWORDS = {
    "ë””ì €íŠ¸": "dessert",
    "ë””ì €íŠ¸ë¥˜": "dessert",
    "dessert": "dessert",
    "ì¼€ì´í¬": "cake",
    "cake": "cake",
    "ì¿ í‚¤": "cookie",
    "cookie": "cookie",
    "ìŒë£Œ": "drink",
    "drink": "drink",
    "ìƒëŸ¬ë“œ": "salad",
    "salad": "salad",
}

DIET_KEYWORDS = {
    "ë‹¤ì´ì–´íŠ¸": "diet",
    "ì €íƒ„ìˆ˜": "low_carb",
    "ì €íƒ„ìˆ˜í™”ë¬¼": "low_carb",
    "ê³ ë‹¨ë°±": "high_protein",
}

# ======== ê²½ë¡œ ì„¤ì • ========

ROOT = Path(__file__).resolve().parent
INDEX_DIR = ROOT / "data" / "test30"
FAISS_PATH = INDEX_DIR / "recipes30.faiss"
ROWMAP_PATH = INDEX_DIR / "rows30.map.csv"
RECIPES_PATH = INDEX_DIR / "recipes30_clean.jsonl"

_embed_model = None
_faiss = None
_rowmap = None
_recipes = None

# ======== OpenAI í´ë¼ì´ì–¸íŠ¸ (ì§€ìˆ˜ ì½”ë“œ) ========

openai_client = None

def _get_openai_client():
    """
    OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê±°ë‚˜ ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜
    (ì§€ìˆ˜ ë²„ì „ì—ì„œ ê°€ì ¸ì˜¨ ì½”ë“œ)
    """
    global openai_client
    if openai_client is None:
        api_key = "put your api_key"
        # api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        openai_client = openai.OpenAI(api_key=api_key)
    return openai_client

# ======== ê³µí†µ ë¡œë” ========

def _load_embed_model():
    global _embed_model
    if _embed_model is None:
        _embed_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
    return _embed_model

def _load_faiss():
    global _faiss
    if _faiss is None:
        _faiss = faiss.read_index(str(FAISS_PATH))
    return _faiss

def _load_rowmap():
    """rows30.map.csv: ì¸ë±ìŠ¤ ë²ˆí˜¸ â†’ title ë§¤í•‘"""
    global _rowmap
    if _rowmap is None:
        _rowmap = pd.read_csv(ROWMAP_PATH)
    return _rowmap

def _load_recipes():
    """recipes30_clean.jsonl: ì¸ë±ìŠ¤ ë²ˆí˜¸ â†’ ë ˆì‹œí”¼ ì „ì²´(doc_text ë“±)"""
    global _recipes
    if _recipes is None:
        recs = []
        if not RECIPES_PATH.exists():
            raise FileNotFoundError(f"ë ˆì‹œí”¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {RECIPES_PATH}")
        with open(RECIPES_PATH, encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    recs.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
        _recipes = recs
    return _recipes

# ======== ì¿¼ë¦¬ ë¹Œë” / ê²€ìƒ‰ ========

def build_query_from_constraints(cons: Dict[str, Any]) -> str:
    """
    ì¶”ì¶œëœ ì œì•½ì„ ê¸°ë°˜ìœ¼ë¡œ RAG ê²€ìƒ‰ìš© ì¿¼ë¦¬ ë¬¸ìì—´ êµ¬ì„±
    ì˜ˆ) chocolate dessert easy recipe quick 15 min
    """
    tokens: List[str] = []

    # 1) ì¬ë£Œ
    for ing in cons.get("main_ingredients", []):
        tokens.append(ing)

    # 2) ì¹´í…Œê³ ë¦¬ (dessert, cake, salad ë“±)
    for cat in cons.get("categories", []):
        tokens.append(cat)

    # 3) ì‹ë‹¨
    diet = cons.get("diet")
    if diet == "high_protein":
        tokens.append("high protein")
    elif diet == "low_carb":
        tokens.append("low carb")
    elif diet == "diet":
        tokens.append("healthy")

    # 4) ì‹œê°„ ì œí•œ
    time_limit = cons.get("time_limit")
    if time_limit:
        tokens.append("quick")
        tokens.append(f"{time_limit} min")

    # 5) í•­ìƒ ë¶™ì´ëŠ” ê¸°ë³¸ í† í°
    tokens.append("easy recipe")

    # í˜¹ì‹œ ì•„ë¬´ê²ƒë„ ëª» ë½‘ì•˜ì„ ë•ŒëŠ” raw_queryë„ ì¡°ê¸ˆ ì„ì–´ì£¼ê¸°
    if len(tokens) <= 2:
        raw = cons.get("raw_query", "").lower()
        if raw:
            tokens.append(raw)

    return " ".join(tokens)


def rag_search(cons: Dict[str, Any], k: int = 5) -> List[Hit]:
    """
    FAISS ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•´ queryì™€ ê°€ì¥ ìœ ì‚¬í•œ ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•˜ê³ ,
    cons(ì¬ë£Œ/ì¹´í…Œê³ ë¦¬)ë¥¼ ì´ìš©í•´ì„œ í•„í„°ë§/ì¬ì •ë ¬í•œ ë’¤ ìƒìœ„ kê°œë§Œ ë°˜í™˜.
    """
    query = build_query_from_constraints(cons)

    model = _load_embed_model()
    index = _load_faiss()
    rowmap = _load_rowmap()
    recipes = _load_recipes()

    # 1) ì¿¼ë¦¬ ì„ë² ë”©
    q = model.encode([query], convert_to_numpy=True).astype("float32")
    faiss.normalize_L2(q)

    # 2) ë„‰ë„‰í•˜ê²Œ pool_kê°œ ë½‘ê¸° (ì˜ˆ: k=5 â†’ ìµœëŒ€ 25ê°œ)
    pool_k = min(max(k * 5, k), index.ntotal)
    scores, ids = index.search(q, pool_k)
    scores, ids = scores[0], ids[0]

    hits: List[Hit] = []
    for score, idx in zip(scores, ids):
        if idx == -1:
            continue

        if 0 <= idx < len(rowmap):
            title = str(rowmap.iloc[idx]["title"])
        else:
            title = f"recipe_{idx}"

        if 0 <= idx < len(recipes):
            rec = recipes[idx]
            text = rec.get("doc_text", "")
        else:
            text = title  # fallback

        hits.append({
            "id": f"r{idx}",          # â˜… main.pyì—ì„œ ìˆ«ì/ID ë‘˜ ë‹¤ ì§€ì›
            "title": title,
            "score": float(score),
            "text": text,
        })

    if not hits:
        hits.append({
            "id": "fallback",
            "title": "ê¸°ë³¸ ë ˆì‹œí”¼",
            "score": 0.0,
            "text": "ì¬ë£Œ ì¤€ë¹„\nì¡°ë¦¬\nì™„ì„±",
        })
        return hits

    # =========================
    # 1ï¸âƒ£ cons ê¸°ë°˜ í•„í„°ë§ (ì¬ë£Œ/ì¹´í…Œê³ ë¦¬)
    # =========================
    filters: List[str] = []

    for ing in cons.get("main_ingredients", []):
        filters.append(ing.lower())

    for cat in cons.get("categories", []):
        filters.append(cat.lower())

    if filters:
        filtered_hits: List[Hit] = []
        for h in hits:
            text_l = (h["title"] + " " + h["text"]).lower()
            # ì¬ë£Œ/ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ ë“¤ì–´ê°€ë©´ í†µê³¼
            if any(f in text_l for f in filters):
                filtered_hits.append(h)

        if filtered_hits:
            hits = filtered_hits

    # (í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ bonus ì ìˆ˜ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥)

    return hits[:k]

# ========= Mock Services (ì§ˆë¬¸ ì²˜ë¦¬ ë“±) =========

def llm_extract_constraints(text: str) -> Dict[str, Any]:
    """
    ê°„ë‹¨í•œ ë£° ê¸°ë°˜ íŒŒì„œ:
    - ì£¼ìš” ì¬ë£Œ(main_ingredients)
    - ì¹´í…Œê³ ë¦¬(ë””ì €íŠ¸, ìƒëŸ¬ë“œ ë“±)
    - ì‹ë‹¨ íƒ€ì…(ê³ ë‹¨ë°± ë“±)
    - ì‹œê°„ ì œí•œ(ëª‡ ë¶„)
    """
    t = text.strip()
    t_lower = t.lower()

    main_ingredients: List[str] = []
    categories: List[str] = []
    diet: Optional[str] = None
    time_limit: Optional[int] = None

    # 1) ì¬ë£Œ í‚¤ì›Œë“œ
    for k, v in INGREDIENT_KEYWORDS.items():
        if k in t or k in t_lower:
            if v not in main_ingredients:
                main_ingredients.append(v)

    # 2) ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ
    for k, v in CATEGORY_KEYWORDS.items():
        if k in t or k in t_lower:
            if v not in categories:
                categories.append(v)

    # 3) ì‹ë‹¨ í‚¤ì›Œë“œ (ë‹¨ì¼ ê°’ìœ¼ë¡œë§Œ)
    for k, v in DIET_KEYWORDS.items():
        if k in t or k in t_lower:
            diet = v
            break

    # 4) ì‹œê°„ ì œí•œ (ì˜ˆ: "15ë¶„", "20 ë¶„")
    m = re.search(r"(\d+)\s*ë¶„", t)
    if m:
        time_limit = int(m.group(1))

    return {
        "raw_query": t,              # ì›ë³¸ ë¬¸ì¥ë„ ê°™ì´ ë³´ê´€
        "main_ingredients": main_ingredients,
        "categories": categories,
        "diet": diet,
        "time_limit": time_limit,
    }


def llm_answer_chef_question(question: str, recipe_text: str) -> str:
    if "ë§ˆëŠ˜" in question and "ì–‘íŒŒ" in question:
        return "ë§›ì€ ë‹¬ë¼ì§€ì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥í•´ìš”. í–¥ì€ ì•½í•´ì§€ê³  ë‹¨ë§›ì´ ì˜¬ë¼ê°‘ë‹ˆë‹¤. ì–‘íŒŒë¥¼ ì˜ê²Œ ì°ì–´ ì´ˆë°˜ì— ì¶©ë¶„íˆ ë³¶ì•„ì£¼ì„¸ìš”."
    return "ê°€ëŠ¥ì€ í•˜ì§€ë§Œ, ê°„Â·ì¡°ë¦¬ ì‹œê°„ì€ ìƒí™©ì— ë§ê²Œ ì¡°ê¸ˆì”© ì¡°ì •í•´ì£¼ì„¸ìš”."

# ========= ì§€ìˆ˜ ë²„ì „ compute_nutrition (OpenAI) =========

def compute_nutrition(recipe_text: str) -> Nutrition:
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë ˆì‹œí”¼ì—ì„œ ì˜ì–‘ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (ì§€ìˆ˜ ë²„ì „ ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    """
    try:
        client = _get_openai_client()

        prompt = f"""
ë‹¤ìŒì€ ìš”ë¦¬ ë ˆì‹œí”¼ì…ë‹ˆë‹¤. ì´ ë ˆì‹œí”¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 1ì¸ë¶„ ê¸°ì¤€ì˜ ì˜ì–‘ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë ˆì‹œí”¼:
{recipe_text}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "calories": ì¹¼ë¡œë¦¬(float),
    "protein_g": ë‹¨ë°±ì§ˆ_ê·¸ë¨(float),
    "fat_g": ì§€ë°©_ê·¸ë¨(float),
    "carbs_g": íƒ„ìˆ˜í™”ë¬¼_ê·¸ë¨(float),
    "note": "ë¶„ì„_ë°©ë²•_ë˜ëŠ”_ì£¼ì˜ì‚¬í•­"
}}

ì£¼ì˜ì‚¬í•­:
- 1ì¸ë¶„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•´ì£¼ì„¸ìš”
- ì¼ë°˜ì ì¸ ì¬ë£Œì˜ ì–‘ì„ ê°€ì •í•˜ì—¬ ê³„ì‚°í•´ì£¼ì„¸ìš”
- ì¡°ë¦¬ ë°©ë²•ë„ ê³ ë ¤í•˜ì—¬ ì¹¼ë¡œë¦¬ë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”
- ìˆ«ìë§Œ ì •í™•íˆ ì…ë ¥í•˜ê³ , JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì˜ì–‘í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìš”ë¦¬ ë ˆì‹œí”¼ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•œ ì˜ì–‘ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=500,
        )

        response_text = response.choices[0].message.content.strip()

        try:
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()

            nutrition_data = json.loads(response_text)

            return {
                "calories": float(nutrition_data.get("calories", 0.0)),
                "protein_g": float(nutrition_data.get("protein_g", 0.0)),
                "fat_g": float(nutrition_data.get("fat_g", 0.0)),
                "carbs_g": float(nutrition_data.get("carbs_g", 0.0)),
                "note": str(nutrition_data.get("note", "OpenAI APIë¡œ ë¶„ì„ë¨")),
            }

        except (json.JSONDecodeError, ValueError, KeyError) as e:
            print(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
            print(f"ì›ë³¸ ì‘ë‹µ: {response_text}")
            return {
                "calories": 500.0,
                "protein_g": 20.0,
                "fat_g": 15.0,
                "carbs_g": 60.0,
                "note": f"OpenAI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš© (ì—ëŸ¬: {str(e)})",
            }

    except Exception as e:
        print(f"OpenAI API í˜¸ì¶œ ì—ëŸ¬: {e}")
        return {
            "calories": 550.0,
            "protein_g": 20.0,
            "fat_g": 15.0,
            "carbs_g": 70.0,
            "note": f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš© (ì—ëŸ¬: {str(e)})",
        }

def append_jsonl(path: str, event: Dict[str, Any]) -> None:
    with open(path, "a", encoding="utf-8") as f:
        f.write(json.dumps(event, ensure_ascii=False) + "\n")

# ========= Agents =========

def planner_agent(state: State) -> State:
    # ë§ˆì§€ë§‰ user ë©”ì‹œì§€ ì°¾ê¸° (íŒ€ì› ë²„ì „ ë¡œì§ ìœ ì§€)
    messages = state.get("messages", [])
    last_user = ""
    if messages:
        last_msg = messages[-1]
        if isinstance(last_msg, dict):
            last_user = last_msg.get("content", "")
        elif hasattr(last_msg, "content"):
            last_user = last_msg.content

    # 1ï¸âƒ£ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì œì•½ ì¶”ì¶œ
    cons = llm_extract_constraints(last_user)

    # 2ï¸âƒ£ RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    query_str = build_query_from_constraints(cons)

    # 3ï¸âƒ£ ê²€ìƒ‰ ì‹¤í–‰ (ê¸°ë³¸ 5ê°œ)
    k = state.get("topk", 5)
    hits = rag_search(cons, k=k)

    msg_query = {
        "role": "system",
        "content": f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query_str}",
    }

    recommendations = []
    for i, h in enumerate(hits, 1):
        recommendations.append(f"{i}. [{h['id']}] {h['title']}")

    msg_result = {
        "role": "assistant",
        "content": (
            f"ìš”ì²­ì„ ë°”íƒ•ìœ¼ë¡œ {len(hits)}ê°œì˜ ìš”ë¦¬ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n\n"
            + "\n".join(recommendations)
            + "\n\nì›í•˜ì‹œëŠ” ë ˆì‹œí”¼ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.\n"
            "ì˜ˆì‹œ: action=choose:r2"
        ),
    }

    return {
        "constraints": cons,
        "candidates": hits,
        "selection_required": True,
        "next_intent": "need_selection",
        "last_agent": "planner",
        "messages": [msg_query, msg_result],
    }


def choose_agent(state: State) -> State:
    act = state.get("action") or ""
    m = re.match(r"choose:(\w+)", act)

    chosen_id: Optional[str] = None
    if m:
        chosen_id = m.group(1)
    elif state.get("candidates"):
        chosen_id = state["candidates"][0]["id"]  # fallback: top-1

    if not chosen_id:
        candidates = state.get("candidates", [])
        recommendations = []
        for i, h in enumerate(candidates, 1):
            recommendations.append(f"{i}. [{h['id']}] {h['title']}")

        return {
            "last_agent": "choose",
            "next_intent": "need_selection",
            "messages": [
                {
                    "role": "assistant",
                    "content": (
                        "ì„ íƒëœ ë ˆì‹œí”¼ê°€ ì—†ì–´ìš”. ì•„ë˜ ëª©ë¡ì—ì„œ ì„ íƒí•´ ì£¼ì„¸ìš”:\n\n"
                        + "\n".join(recommendations)
                        + "\n\nì˜ˆì‹œ: action=choose:r2"
                    ),
                }
            ],
        }

    hit = next((h for h in state.get("candidates", []) if h["id"] == chosen_id), None)
    if not hit:
        candidates = state.get("candidates", [])
        recommendations = []
        for i, h in enumerate(candidates, 1):
            recommendations.append(f"{i}. [{h['id']}] {h['title']}")

        return {
            "last_agent": "choose",
            "next_intent": "need_selection",
            "messages": [
                {
                    "role": "assistant",
                    "content": (
                        f"'{chosen_id}'ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ IDì˜ˆìš”. ì•„ë˜ ëª©ë¡ì—ì„œ ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”:\n\n"
                        + "\n".join(recommendations)
                        + "\n\nì˜ˆì‹œ: action=choose:r2"
                    ),
                }
            ],
        }

    steps = [s for s in hit["text"].splitlines() if s.strip()]

    return {
        "selected_id": hit["id"],
        "recipe_text": hit["text"],
        "steps": steps,
        "step_idx": 0,
        "selection_required": False,
        "last_agent": "choose",
        "next_intent": "cook_next",
        "messages": [
            {
                "role": "assistant",
                "content": (
                    f"âœ… '{hit['title']}' ë ˆì‹œí”¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤!\n\n"
                    f"ì´ {len(steps)}ë‹¨ê³„ì˜ ì¡°ë¦¬ ê³¼ì •ì´ ìˆìŠµë‹ˆë‹¤.\n"
                    f"'action=next_step'ìœ¼ë¡œ ì¡°ë¦¬ë¥¼ ì‹œì‘í•´ ì£¼ì„¸ìš”."
                ),
            }
        ],
    }


def chef_agent(state: State) -> State:
    act = (state.get("action") or "").lower()
    steps = state.get("steps", []) or []
    idx = state.get("step_idx", 0)

    # 1) ì§ˆë¬¸ ì²˜ë¦¬
    if act.startswith("ask:"):
        q = state["action"][len("ask:") :].strip()
        ans = llm_answer_chef_question(q, state.get("recipe_text", ""))
        return {
            "last_agent": "chef",
            "next_intent": "cook_next",
            "messages": [
                {
                    "role": "assistant",
                    "content": f"ğŸ’¬ Q: {q}\n\nğŸ“ A: {ans}",
                }
            ],
        }

    # 2) ë‹¤ìŒ ìŠ¤í… ì§„í–‰
    if act == "next_step" and idx < len(steps):
        step = steps[idx]
        progress = f"[{idx+1}/{len(steps)}]"
        return {
            "step_idx": idx + 1,
            "last_agent": "chef",
            "next_intent": "cook_next",
            "messages": [
                {
                    "role": "assistant",
                    "content": (
                        f"ğŸ‘¨â€ğŸ³ {progress} {step}\n\n"
                        f"{'ë‹¤ìŒ ë‹¨ê³„ë¡œ: action=next_step' if idx+1 < len(steps) else 'ì¡°ë¦¬ ì™„ë£Œ! action=stopìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.'}"
                    ),
                }
            ],
        }

    # 3) ìŠ¤í… ì¢…ë£Œ â†’ ì˜ì–‘ ë¶„ì„
    return {
        "last_agent": "chef",
        "next_intent": "analyze_nutrition",
        "messages": [
            {
                "role": "assistant",
                "content": "ğŸ‰ ì¡°ë¦¬ë¥¼ ë§ˆì³¤ë‹¤ê³  íŒë‹¨í–ˆì–´ìš”. ì´ì œ ì˜ì–‘ ì •ë³´ë¥¼ ê³„ì‚°í• ê²Œìš”.",
            }
        ],
    }


def nutrition_agent(state: State) -> State:
    nut = compute_nutrition(state.get("recipe_text", "") or "")
    text = (
        f"ğŸ“Š ì˜ì–‘ ì •ë³´ (ëŒ€ëµ ì¶”ì •)\n\n"
        f"â€¢ ì¹¼ë¡œë¦¬: {nut['calories']}kcal\n"
        f"â€¢ ë‹¨ë°±ì§ˆ: {nut['protein_g']}g\n"
        f"â€¢ ì§€ë°©: {nut['fat_g']}g\n"
        f"â€¢ íƒ„ìˆ˜í™”ë¬¼: {nut['carbs_g']}g\n\n"
        f"({nut['note']})"
    )

    return {
        "nutrition": nut,
        "last_agent": "nutrition",
        "next_intent": "write_memory",
        "messages": [{"role": "assistant", "content": text}],
    }


def memory_agent(state: State) -> State:
    ev = {
        "ts": time.time(),
        "recipe_id": state.get("selected_id"),
        "prefs": state.get("prefs", {}),
        "nutrition": state.get("nutrition"),
    }
    append_jsonl("data/user_memory.jsonl", ev)

    return {
        "memory_event": ev,
        "last_agent": "memory",
        "next_intent": "finished",
        "messages": [
            {
                "role": "assistant",
                "content": "ğŸ’¾ ì´ë²ˆ ìš”ë¦¬ ê¸°ë¡ì„ ì €ì¥í–ˆì–´ìš”. ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!",
            }
        ],
    }
